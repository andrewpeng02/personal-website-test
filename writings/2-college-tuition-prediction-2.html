<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Blog title</title>

    <link rel="stylesheet" href="../style.css" />
    <link rel="stylesheet" href="writings-style.css" />
    <link rel="stylesheet" href="../prism/prism.css" />

    <script src="../components/header.js" type="text/javascript" defer></script>
    <script
      src="../components/nav-footer.js"
      type="text/javascript"
      defer
    ></script>
    <script src="../components/footer.js" type="text/javascript" defer></script>
    <script src="writings.js" type="text/javascript" defer></script>
  </head>
  <body>
    <div class="container">
      <header-component></header-component>

      <main>
        <h1 class="title"></h1>
        <p class="date"></p>
        <!-- Blog content goes below -->
        <div class="blog-content">
          <p>
            Now that I've finished preparing the data, it's time to build the
            model!
          </p>
          <figure>
            <img
              src="/images/2-college-tuition-prediction-2/college.jpg"
              alt="A University of Oxford building"
              style="width: 100%"
            />
            <figcaption>
              <p>
                <a
                  href="https://unsplash.com/photos/_QstzxTWnXY?utm_source=unsplash&utm_medium=referral&utm_content=creditShareLink"
                  >A University of Oxford building</a
                >
              </p>
            </figcaption>
          </figure>
          <p>
            I chose to try sklearn's support vector machine and random forest,
            as well as xgboost because predicting college tuition should be a
            relatively simple task. To find the best model, I used sklearn's
            GridSearchCV to brute force the parameters for each model.
            GridSearchCV takes the model (in this case a support vector
            regressor), a parameter grid (7*5*7=245 total combinations), a
            scoring method (regression so I'll use mean squared error), and
            number of folds for cross validation.
          </p>
          <pre
            class="line-numbers"
          ><code class="language-python">model = svm.SVR()
grid_values = {'gamma': [0.01, 0.03, 0.1, 0.3, 1, 3, 9], 
                'C': [0.1, 0.3, 1, 3, 9], 
                'epsilon': [0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1]}
grid_search = GridSearchCV(model, param_grid=grid_values, n_jobs=-1, scoring='neg_mean_squared_error', cv=3)
grid_search.fit(X_train, y_train)</code></pre>
          <p>
            Using GridSearchCV is similar for a random forest regressor and
            xgboost regressor, but it takes a different parameter grid. Here are
            the results:
          </p>
          <figure>
            <img
              src="/images/2-college-tuition-prediction-2/results.png"
              alt="A graph of the results"
              style="width: 60%"
            />
            <figcaption>
              <p>A bar graph comparing the results of the models</p>
            </figcaption>
          </figure>
          <p>
            Unsurprisingly, the xgboost model did the best, followed by random
            forest and SVR. Here is a scatterplot of the xgboost model
            predicting on the test set:
          </p>
          <figure>
            <img
              src="/images/2-college-tuition-prediction-2/predictions.png"
              alt="A scatterplot of targets vs predictions"
              style="width: 60%"
            />
            <figcaption>
              <p>A scatterplot of targets vs predictions</p>
            </figcaption>
          </figure>
          <p>
            Visualizing the plot confirmed my hypothesis that the model would do
            best at lower tuition amounts. With xgboost, I can retrieve the
            feature importance and plot it as well.
          </p>
          <figure>
            <img
              src="/images/2-college-tuition-prediction-2/feature_importance.png"
              alt="Feature importance graph"
              style="width: 100%"
            />
            <figcaption>
              <p>Feature importance graph</p>
            </figcaption>
          </figure>
          <p>
            Admissions yield and professor salary contributed the most, while my
            categorical features regarding college size and location provided
            little predictive power.
          </p>
          <p>
            Full code is located over on my
            <a
              href="https://github.com/andrewpeng02/college-tuition/tree/master"
              >GitHub</a
            >.
          </p>
        </div>
      </main>

      <nav-footer-component></nav-footer-component>
      <footer-component></footer-component>
    </div>

    <script src="../prism/prism.js"></script>
  </body>
</html>
